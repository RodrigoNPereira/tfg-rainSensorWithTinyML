{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variáveis, imports e funções primárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1717696840447,
     "user": {
      "displayName": "Bruno vilela batista",
      "userId": "05215065962813455378"
     },
     "user_tz": 180
    },
    "id": "qIAw3qALozH7"
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "import wave\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1717696845415,
     "user": {
      "displayName": "Bruno vilela batista",
      "userId": "05215065962813455378"
     },
     "user_tz": 180
    },
    "id": "Kp1gmrrpozH-"
   },
   "outputs": [],
   "source": [
    "PACKET_SIZE = 4\n",
    "ID_SIZE = 4\n",
    "TIMESTAMP_SIZE = 8\n",
    "AUDIO_SAMPLING_FREQ = 16384\n",
    "AUDIO_SAMPLE_SIZE = 3\n",
    "AUDIO_SIZE = AUDIO_SAMPLE_SIZE * AUDIO_SAMPLING_FREQ\n",
    "BME280_SIZE = 4 * 4\n",
    "MECHANICAL_SIZE = 3 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1717696845415,
     "user": {
      "displayName": "Bruno vilela batista",
      "userId": "05215065962813455378"
     },
     "user_tz": 180
    },
    "id": "SRx9AxBrozH-"
   },
   "outputs": [],
   "source": [
    "CHECKSUM = True # checksum has been implemented from 2023-08-09 at 15:00\n",
    "SAMPLE_SIZE = PACKET_SIZE + ID_SIZE + TIMESTAMP_SIZE + AUDIO_SIZE + BME280_SIZE + MECHANICAL_SIZE\n",
    "if CHECKSUM:\n",
    "    SAMPLE_SIZE+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 419,
     "status": "ok",
     "timestamp": 1717696846195,
     "user": {
      "displayName": "Bruno vilela batista",
      "userId": "05215065962813455378"
     },
     "user_tz": 180
    },
    "id": "67ZTdDPDozH_"
   },
   "outputs": [],
   "source": [
    "# Define paths for saving data\n",
    "save_in_directory = \"./sem43Data\"\n",
    "os.makedirs(save_in_directory, exist_ok=True)\n",
    "csv_filename = f\"{save_in_directory}/sem43.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1717696851865,
     "user": {
      "displayName": "Bruno vilela batista",
      "userId": "05215065962813455378"
     },
     "user_tz": 180
    },
    "id": "gEWwVYIhozH_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_42860\\1088622479.py:1: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "*  \\brief     calibration.py\n",
    "*  \\details   Python script to get wind direction from raw data\n",
    "*  \\author    Mateo Haro\n",
    "*  \\version   1.1\n",
    "*  \\date      2022-08-21\n",
    "*  \\pre       None\n",
    "*  \\copyright (c) 2022 CSEM\n",
    "*\n",
    "*   CSEM S.A.\n",
    "*   Jaquet-Droz 1\n",
    "*   CH-2000 Neuchâtel\n",
    "*   http://www.csem.ch\n",
    "*\n",
    "*\n",
    "*   THIS PROGRAM IS CONFIDENTIAL AND CANNOT BE DISTRIBUTED\n",
    "*   WITHOUT THE CSEM PRIOR WRITTEN AGREEMENT.\n",
    "*\n",
    "*   CSEM is the owner of this source code and is authorised to use, to modify\n",
    "*   and to keep confidential all new modifications of this code.\n",
    "*\n",
    "\"\"\"\n",
    "\n",
    "WMK_NUM_ANGLES = 16\n",
    "SFE_WIND_VANE_DEGREES_PER_INDEX = 360/WMK_NUM_ANGLES\n",
    "\n",
    "class Station:\n",
    "   def __init__(self, id, calibration):\n",
    "      self.id = id\n",
    "      self.vaneADCValues = calibration\n",
    "\n",
    "   def getWindDirection(self, rawADC):\n",
    "      \"\"\"\n",
    "      We'll loop through all possible directions to find which is closest\n",
    "      to our measurement, using a simple linear search. closestDifference is\n",
    "      initialized to max 16-bit signed value (2^15 - 1 = 32,767)\n",
    "      \"\"\"\n",
    "      closestDifference = 32767\n",
    "      closestIndex = 0\n",
    "\n",
    "      for i in range(WMK_NUM_ANGLES):\n",
    "         # Compute the difference between the ADC value for this direction and what we measured\n",
    "         adcDifference = self.vaneADCValues[i] - rawADC\n",
    "\n",
    "         # We only care about the magnitude of the difference\n",
    "         adcDifference = abs(adcDifference)\n",
    "\n",
    "         # Check if this different is less than our closest so far\n",
    "         if adcDifference < closestDifference:\n",
    "            # This resistance is closer, update closest resistance and index\n",
    "            closestDifference = adcDifference\n",
    "            closestIndex = i\n",
    "\n",
    "      # Now compute the wind direction in degrees\n",
    "      direction = closestIndex * SFE_WIND_VANE_DEGREES_PER_INDEX\n",
    "\n",
    "      # Return direction in degrees\n",
    "      # As an indication: 0deg is North and 90deg is East\n",
    "      return direction\n",
    "\n",
    "# calibration for mechanical station associated to CSEMAurora1\n",
    "calibration1 = [2955, 1437, 1658, 172, 208, 105, 568, 336, 965, 797, 2320, 2205, 3876, 3154, 3477, 2609]\n",
    "station1 = Station(1, calibration1)\n",
    "\n",
    "# calibration for mechanical station associated to CSEMAurora2\n",
    "calibration2 = [3050, 1490, 1720, 185, 225, 113, 594, 355, 1007, 831, 2405, 2282, 3930, 3240, 3550, 2700]\n",
    "station2 = Station(2, calibration2)\n",
    "\n",
    "# calibration for mechanical station associated to CSEMAurora3\n",
    "calibration3 = [3012, 1481, 1703, 202, 240, 131, 602, 370, 1008, 835, 2381, 2256, 3865, 3201, 3500, 2670]\n",
    "station3 = Station(3, calibration2)\n",
    "\n",
    "# calibration for mechanical station associated to CSEMAurora4\n",
    "calibration4 = [3018, 1472, 1702, 185, 222, 112, 590, 351, 993, 821, 2375, 2256, 3935, 3217, 3543, 2672]\n",
    "station3 = Station(4, calibration2)\n",
    "\n",
    "# calibration for mechanical station associated to CSEMAurora5\n",
    "calibration5 = [2927, 1423, 1642, 158, 192, 86, 555, 321, 945, 778, 2300, 2181, 3822, 3119, 3434, 2587]\n",
    "station3 = Station(5, calibration2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1717696854531,
     "user": {
      "displayName": "Bruno vilela batista",
      "userId": "05215065962813455378"
     },
     "user_tz": 180
    },
    "id": "a4hqHEQUozIA"
   },
   "outputs": [],
   "source": [
    "#limites para os labels\n",
    "#Chuva fraca: menos de 1 mm/h.\n",
    "#Chuva moderada: de 2,5 até 10 mm/h.\n",
    "#Chuva forte: a partir de 10mm\n",
    "rain_limits = [0.5, 2, 4] #mm/hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1717696857728,
     "user": {
      "displayName": "Bruno vilela batista",
      "userId": "05215065962813455378"
     },
     "user_tz": 180
    },
    "id": "1Rb6q7quozIA"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "# Function to convert filename to datetime object for sorting\n",
    "def filename_to_datetime(filename):\n",
    "    match = re.search(r'(\\d{4}-\\d{2}-\\d{2})_(\\d+)', filename)\n",
    "    if match:\n",
    "        date_str, hour_str = match.groups()\n",
    "        return dt.strptime(f'{date_str} {hour_str}', '%Y-%m-%d %H')\n",
    "    else:\n",
    "        return dt.min  # return minimum datetime if no match\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geração do csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#example multiple files\n",
    "def read_data_multiple_files_hour(directory, save_in_directory,csv_filename):\n",
    "    total_temperature = 0\n",
    "    total_pressure = 0\n",
    "    total_altitude = 0\n",
    "    total_humidity = 0\n",
    "    total_wind_count = 0\n",
    "    total_rain_count = 0\n",
    "    total_wind_direction = 0\n",
    "    contagemAmostras = 0\n",
    "    pulses = []\n",
    "    #sound_data = []\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_in_directory, exist_ok=True)\n",
    "\n",
    "    # Setup for CSV file\n",
    "    csv_headers = ['timestamp', 'temperature', 'pressure', 'altitude', 'humidity', 'wind_count', 'wind_km_h','rain_count', 'rain_mm', 'wind_direction', 'audio_file', 'label', 'amostras','pulses']\n",
    "\n",
    "    # We will check if the CSV already exists to decide whether to write headers or not\n",
    "    write_headers = not os.path.exists(csv_filename)\n",
    "\n",
    "    with open(csv_filename, 'a', newline='') as csv_file:\n",
    "        csv_writer = csv.DictWriter(csv_file, fieldnames=csv_headers)\n",
    "        if write_headers:\n",
    "            csv_writer.writeheader()\n",
    "\n",
    "        # Get a list of all .dat files in the directory\n",
    "        dat_files = glob.glob(os.path.join(directory, '*.dat'))\n",
    "\n",
    "        # Sort the files by filename\n",
    "        dat_files.sort(key=filename_to_datetime)\n",
    "\n",
    "        for file_name in dat_files:\n",
    "            try: \n",
    "                print(f\"Processing {file_name}...\")\n",
    "                # open the .dat file with \"rb\" (read binary) mode\n",
    "                with open(file_name, \"rb\") as f:\n",
    "                    data = f.read()\n",
    "                    f.close()\n",
    "                \n",
    "                #o timestamp deve dever o nome do arquivo raw_data_CSEMAurora1_2023-08-28_0 alterado para o formato 2023-08-27 00_00_00\n",
    "                timestamp_name = file_name.split('_')[3] + ' ' + file_name.split('_')[4][:-4] + '_' + '00' + '_' + '00'\n",
    "\n",
    "                # read the binary data\n",
    "                num_sample = int(len(data) / SAMPLE_SIZE) # should be an integer\n",
    "                for j in range(num_sample):\n",
    "                    index = j * SAMPLE_SIZE\n",
    "                    packet_size = struct.unpack(\"<L\", data[index: index + PACKET_SIZE])[0] # should be equal to SAMPLE_SIZE\n",
    "                    index += PACKET_SIZE\n",
    "                    packet_id = struct.unpack(\"<L\", data[index: index + ID_SIZE])[0]\n",
    "                    index += ID_SIZE\n",
    "                    timestamp = struct.unpack(\"<Q\", data[index: index + TIMESTAMP_SIZE])[0]\n",
    "                    index += TIMESTAMP_SIZE\n",
    "                    samples_raw =  data[index: index + AUDIO_SIZE]\n",
    "                    index += AUDIO_SIZE\n",
    "                    bme_values = list(struct.iter_unpack(\"<f\", data[index: index + BME280_SIZE]))\n",
    "                    index += BME280_SIZE\n",
    "                    mechanical_values = list(struct.iter_unpack(\"<I\", data[index: index + MECHANICAL_SIZE]))\n",
    "                    index += MECHANICAL_SIZE\n",
    "\n",
    "                    # post process and save the BME and mechanical data in a dict\n",
    "                    BME_data = {\"temperature\":bme_values[0][0], \"pressure\":bme_values[1][0], \"altitude\":bme_values[2][0], \"humidity\":bme_values[3][0]}\n",
    "                    mechanical_data = {\"wind_count\":mechanical_values[0][0],\"rain_count\":mechanical_values[1][0],\"wind_direction\":mechanical_values[2][0]}\n",
    "\n",
    "                    if mechanical_data['rain_count'] > 0:\n",
    "                        pulses.append(j)\n",
    "\n",
    "                    total_temperature += BME_data['temperature']\n",
    "                    total_pressure += BME_data['pressure']\n",
    "                    total_altitude += BME_data['altitude']\n",
    "                    total_humidity += BME_data['humidity']\n",
    "                    total_wind_count += mechanical_data['wind_count']\n",
    "                    total_rain_count += mechanical_data['rain_count']\n",
    "                    total_wind_direction += mechanical_data['wind_direction']\n",
    "                    contagemAmostras += 1\n",
    "                \n",
    "                med_temperature = total_temperature / contagemAmostras\n",
    "                med_pressure = total_pressure / contagemAmostras\n",
    "                med_altitude = total_altitude / contagemAmostras\n",
    "                med_humidity = total_humidity / contagemAmostras\n",
    "                med_wind_count = total_wind_count / contagemAmostras\n",
    "                med_wind_direction = total_wind_direction / contagemAmostras\n",
    "                wind_km_h = med_wind_count * 2.4\n",
    "                rain_mm = total_rain_count * 0.2794\n",
    "                wind_deg = station1.getWindDirection(med_wind_direction)\n",
    "                label = ''\n",
    "                if rain_mm < rain_limits[0]:\n",
    "                    label = 0\n",
    "                elif rain_mm < rain_limits[1]:\n",
    "                    label = 1\n",
    "                elif rain_mm < rain_limits[2]:\n",
    "                    label = 2\n",
    "                else:\n",
    "                    label = 3\n",
    "\n",
    "                row_data = {\n",
    "                    'timestamp': timestamp_name,\n",
    "                    'temperature': med_temperature,\n",
    "                    'pressure': med_pressure,\n",
    "                    'altitude': med_altitude,\n",
    "                    'humidity': med_humidity,\n",
    "                    'wind_count': med_wind_count,\n",
    "                    'wind_km_h': wind_km_h,\n",
    "                    'rain_count': total_rain_count,\n",
    "                    'rain_mm': rain_mm,\n",
    "                    'wind_direction': wind_deg,\n",
    "                    'audio_file': 'null',\n",
    "                    'label': label,\n",
    "                    'amostras': contagemAmostras,\n",
    "                    'pulses': pulses\n",
    "                }\n",
    "                csv_writer.writerow(row_data)\n",
    "\n",
    "                total_temperature = 0\n",
    "                total_pressure = 0\n",
    "                total_altitude = 0\n",
    "                total_humidity = 0\n",
    "                total_wind_count = 0\n",
    "                total_rain_count = 0\n",
    "                total_wind_direction = 0\n",
    "                contagemAmostras = 0\n",
    "                pulses = []\n",
    "                #sound_data = []\n",
    "                time_ini = ''\n",
    "                time_ini_name =''\n",
    "            except:\n",
    "                \n",
    "                print(f\"Error processing {file_name}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_0.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_1.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_2.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_3.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_4.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_5.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_6.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_7.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_8.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_9.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_10.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_11.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_12.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_13.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_14.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_15.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_16.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_17.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_18.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_19.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_20.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_21.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_22.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-26_23.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_0.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_1.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_2.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_3.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_4.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_5.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_6.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_7.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_8.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_9.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_10.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_11.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_12.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_13.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_14.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_15.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_16.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_17.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_18.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_19.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_20.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_21.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_22.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-27_23.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_0.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_1.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_2.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_3.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_4.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_5.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_6.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_7.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_8.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_9.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_10.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_11.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_12.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_13.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_14.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_15.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_16.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_17.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_18.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_19.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_20.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_21.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_22.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-28_23.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_0.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_1.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_2.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_3.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_4.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_5.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_6.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_7.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_8.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_9.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_10.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_11.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_12.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_13.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_14.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_15.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_16.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_17.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_18.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_19.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_20.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_21.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_22.dat...\n",
      "Processing ./rawdata43\\raw_data_CSEMAurora1_2023-10-29_23.dat...\n"
     ]
    }
   ],
   "source": [
    "read_data_multiple_files_hour('./rawdata43', save_in_directory, csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_42860\\600523390.py:8: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df.to_csv('sem43Data\\sem43.csv', index=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['2023-10-26', '2023-10-26', '2023-10-26', '2023-10-26',\n",
       "       '2023-10-26', '2023-10-26', '2023-10-27', '2023-10-27',\n",
       "       '2023-10-26_0', '2023-10-26_1', '2023-10-26_2', '2023-10-26_3',\n",
       "       '2023-10-26_4', '2023-10-26_5', '2023-10-26_6', '2023-10-26_7',\n",
       "       '2023-10-26_8', '2023-10-26_9', '2023-10-26_10', '2023-10-26_11',\n",
       "       '2023-10-26_12', '2023-10-26_13', '2023-10-26_14', '2023-10-26_15',\n",
       "       '2023-10-26_16', '2023-10-26_17', '2023-10-26_18', '2023-10-26_19',\n",
       "       '2023-10-26_20', '2023-10-26_21', '2023-10-26_22', '2023-10-26_23',\n",
       "       '2023-10-27_0', '2023-10-27_1', '2023-10-27_2', '2023-10-27_3',\n",
       "       '2023-10-27_4', '2023-10-27_5', '2023-10-27_6', '2023-10-27_7',\n",
       "       '2023-10-27_8', '2023-10-27_9', '2023-10-27_10', '2023-10-27_11',\n",
       "       '2023-10-27_12', '2023-10-27_13', '2023-10-27_14', '2023-10-27_15',\n",
       "       '2023-10-27_16', '2023-10-27_17', '2023-10-27_18', '2023-10-27_19',\n",
       "       '2023-10-27_20', '2023-10-27_21', '2023-10-27_22', '2023-10-27_23',\n",
       "       '2023-10-28_0', '2023-10-28_1', '2023-10-28_2', '2023-10-28_3',\n",
       "       '2023-10-28_4', '2023-10-28_5', '2023-10-28_6', '2023-10-28_7',\n",
       "       '2023-10-28_8', '2023-10-28_9', '2023-10-28_10', '2023-10-28_11',\n",
       "       '2023-10-28_12', '2023-10-28_13', '2023-10-28_14', '2023-10-28_15',\n",
       "       '2023-10-28_16', '2023-10-28_17', '2023-10-28_18', '2023-10-28_19',\n",
       "       '2023-10-28_20', '2023-10-28_21', '2023-10-28_22', '2023-10-28_23',\n",
       "       '2023-10-29_0', '2023-10-29_1', '2023-10-29_2', '2023-10-29_3',\n",
       "       '2023-10-29_4', '2023-10-29_5', '2023-10-29_6', '2023-10-29_7',\n",
       "       '2023-10-29_8', '2023-10-29_9', '2023-10-29_10', '2023-10-29_11',\n",
       "       '2023-10-29_12', '2023-10-29_13', '2023-10-29_14', '2023-10-29_15',\n",
       "       '2023-10-29_16', '2023-10-29_17', '2023-10-29_18', '2023-10-29_19',\n",
       "       '2023-10-29_20', '2023-10-29_21', '2023-10-29_22', '2023-10-29_23'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sem43Data/sem43.csv') \n",
    "#mudar a clouna do csv para ficar no formato 2023-08-28_0, onde o ultimo numero é a hora\n",
    "df['timestamp'] = df['timestamp'].apply(lambda x: x.split('_')[0])\n",
    "#subtituir espaço vaizo por _\n",
    "df['timestamp'] = df['timestamp'].apply(lambda x: x.replace(' ', '_'))\n",
    "df.head()\n",
    "#salvar esse df em um csv\n",
    "df.to_csv('sem43Data\\sem43.csv', index=False)\n",
    "\n",
    "#contar quantas linhas tem para cada label\n",
    "df['label'].value_counts()\n",
    "df['timestamp'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\bruno\\AppData\\Local\\Temp\\ipykernel_42860\\2519725551.py:1: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv('sem43Data\\sem43.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sem43Data\\sem43.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#example multiple files\n",
    "def save_audio_data_multiple_files_hour(directory, save_in_directory):\n",
    "\n",
    "    countLowRain = 20\n",
    "    countNoRain = 0\n",
    "    countMediumRain = 99\n",
    "    countHighRain = 99\n",
    "    sound_data = []\n",
    "    label_name = ''\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_in_directory, exist_ok=True)\n",
    "\n",
    "    #create directories for each label\n",
    "    os.makedirs(f\"{save_in_directory}/NoRain\", exist_ok=True)\n",
    "    os.makedirs(f\"{save_in_directory}/LowRain\", exist_ok=True)\n",
    "    os.makedirs(f\"{save_in_directory}/MediumRain\", exist_ok=True)\n",
    "    os.makedirs(f\"{save_in_directory}/HighRain\", exist_ok=True)\n",
    "\n",
    "    # Get a list of all .dat files in the directory\n",
    "    dat_files = glob.glob(os.path.join(directory, '*.dat'))\n",
    "\n",
    "    # Sort the files by filename\n",
    "    dat_files.sort(key=filename_to_datetime)\n",
    "   \n",
    "    for file_name in dat_files:\n",
    "        #try: \n",
    "            print(f\"Processing {file_name}...\")         \n",
    "            \n",
    "            #o timestamp deve dever o nome do arquivo raw_data_CSEMAurora1_2023-08-28_0 alterado para o formato 2023-08-27 00_00_00\n",
    "            #ele será comparado com o a coluna timestamp do csv, dependendo do label, o arquivo de audio será salvo em uma pasta específica\n",
    "            timestamp_name = file_name.split('_')[3] + '_' + file_name.split('_')[4][:-4]\n",
    "            print(timestamp_name)\n",
    "            if timestamp_name in df['timestamp'].values:\n",
    "                print(f\"Processing {timestamp_name}...\")\n",
    "                label = df.loc[df['timestamp'] == timestamp_name, 'label'].values[0]\n",
    "                print(f\"Label: {label}\")\n",
    "\n",
    "            #if the four counts are zero, break the loop\n",
    "            if countNoRain == 0 and countLowRain == 0 and countMediumRain == 0 and countHighRain == 0:\n",
    "                break\n",
    "\n",
    "            match label:\n",
    "                case 0:\n",
    "                    if countNoRain == 0:\n",
    "                        continue\n",
    "                    countNoRain -= 1\n",
    "                    label_name = 'NoRain'\n",
    "                case 1:\n",
    "                    if countLowRain == 0:\n",
    "                        continue\n",
    "                    countLowRain -= 1\n",
    "                    label_name = 'LowRain'\n",
    "                case 2:\n",
    "                    if countMediumRain == 0:\n",
    "                        continue\n",
    "                    countMediumRain -= 1\n",
    "                    label_name = 'MediumRain'\n",
    "                case 3:\n",
    "                    if countHighRain == 0:\n",
    "                        continue\n",
    "                    countHighRain -= 1\n",
    "                    label_name = 'HighRain'\n",
    "            \n",
    "            # open the .dat file with \"rb\" (read binary) mode\n",
    "            with open(file_name, \"rb\") as f:\n",
    "                data = f.read()\n",
    "                f.close()            \n",
    "\n",
    "            # read the binary data\n",
    "            for pulses in df.loc[df['timestamp'] == timestamp_name, 'pulses']:\n",
    "                #convertendo a string para lista e tirando espacos vazios\n",
    "                pulses = pulses[1:-1].split(',')\n",
    "                \n",
    "                for pulse in pulses:\n",
    "                    sound_data = []\n",
    "                    pulse = int(pulse)\n",
    "                    start_index = max(0, pulse - 15)\n",
    "                    end_index = min(len(data), pulse + 15)\n",
    "                    for j in range(start_index, end_index):\n",
    "                        index = j * SAMPLE_SIZE\n",
    "                        index += PACKET_SIZE\n",
    "                        # packet_id = struct.unpack(\"<L\", data[index: index + ID_SIZE])[0]\n",
    "                        index += ID_SIZE\n",
    "                        # timestamp = struct.unpack(\"<Q\", data[index: index + TIMESTAMP_SIZE])[0]\n",
    "                        index += TIMESTAMP_SIZE\n",
    "                        samples_raw =  data[index: index + AUDIO_SIZE]\n",
    "                        index += AUDIO_SIZE\n",
    "                        index += BME280_SIZE\n",
    "                        index += MECHANICAL_SIZE\n",
    "\n",
    "                        # post process the audio samples collected with I2S protocol\n",
    "                        samples = []\n",
    "                        for i in range(0, int(AUDIO_SIZE / AUDIO_SAMPLE_SIZE)): # get the number of audio samples, not the number of bytes\n",
    "                            value =     samples_raw[AUDIO_SAMPLE_SIZE*i      ] << 16\n",
    "                            value +=    samples_raw[AUDIO_SAMPLE_SIZE*i + 1  ] << 8\n",
    "                            value +=    samples_raw[AUDIO_SAMPLE_SIZE*i + 2  ]\n",
    "                            if(value>2**23 - 1):\n",
    "                                value = -(2**24 - value)\n",
    "                            samples.append(value)        \n",
    "                        sound_data += samples\n",
    "                    \n",
    "                                    \n",
    "                    #save sound data in a .wav file\n",
    "                    sound_file = f\"{save_in_directory}/{label_name}/{timestamp_name}_{pulse}.wav\"\n",
    "                    obj = wave.open(sound_file, \"w\")\n",
    "                    obj.setnchannels(1)\n",
    "                    obj.setsampwidth(AUDIO_SAMPLE_SIZE)\n",
    "                    obj.setframerate(AUDIO_SAMPLING_FREQ)\n",
    "                    data_as_bytes = [struct.pack(\"<i\", sample) for sample in sound_data] # store it as 4 bytes in LSB format (little endian)\n",
    "                    for data_bytes in data_as_bytes:\n",
    "                        obj.writeframes(data_bytes[0:3]) # remove the fourth unused byte one ().\n",
    "                    obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./test43\\raw_data_CSEMAurora1_2023-10-26_18.dat...\n",
      "2023-10-26_18\n",
      "Processing 2023-10-26_18...\n",
      "Label: 1\n",
      "Processing ./test43\\raw_data_CSEMAurora1_2023-10-26_19.dat...\n",
      "2023-10-26_19\n",
      "Processing 2023-10-26_19...\n",
      "Label: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test43\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m save_in_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./testaudios43\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43msave_audio_data_multiple_files_hour\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_in_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 112\u001b[0m, in \u001b[0;36msave_audio_data_multiple_files_hour\u001b[1;34m(directory, save_in_directory)\u001b[0m\n\u001b[0;32m    110\u001b[0m data_as_bytes \u001b[38;5;241m=\u001b[39m [struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<i\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m sound_data] \u001b[38;5;66;03m# store it as 4 bytes in LSB format (little endian)\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data_bytes \u001b[38;5;129;01min\u001b[39;00m data_as_bytes:\n\u001b[1;32m--> 112\u001b[0m     \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriteframes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_bytes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# remove the fourth unused byte one ().\u001b[39;00m\n\u001b[0;32m    113\u001b[0m obj\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\wave.py:578\u001b[0m, in \u001b[0;36mWave_write.writeframes\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriteframesraw(data)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datalength \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datawritten:\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_patchheader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bruno\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\wave.py:636\u001b[0m, in \u001b[0;36mWave_write._patchheader\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_form_length_pos, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mwrite(struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<L\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m36\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datawritten))\n\u001b[1;32m--> 636\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_length_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mwrite(struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<L\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_datawritten))\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file\u001b[38;5;241m.\u001b[39mseek(curpos, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#executar a função\n",
    "directory = './test43'\n",
    "save_in_directory = './testaudios43'\n",
    "save_audio_data_multiple_files_hour(directory, save_in_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 3600.0 seconds\n",
      "Number of chunks: 120\n"
     ]
    }
   ],
   "source": [
    "def split_audio(audio_file, save_in_directory):\n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(save_in_directory, exist_ok=True)\n",
    "\n",
    "    # Open the audio file\n",
    "    obj = wave.open(audio_file, \"r\")\n",
    "    num_frames = obj.getnframes()\n",
    "    frame_rate = obj.getframerate()\n",
    "    num_channels = obj.getnchannels()\n",
    "    sample_width = obj.getsampwidth()\n",
    "    duration = num_frames / frame_rate\n",
    "    num_chunks = int(duration / 30) # 30 seconds chunks\n",
    "    print(f\"Duration: {duration} seconds\")\n",
    "    print(f\"Number of chunks: {num_chunks}\")\n",
    "\n",
    "    # Read the audio data\n",
    "    audio_data = obj.readframes(num_frames)\n",
    "    obj.close()\n",
    "\n",
    "    # Split the audio data into 30 seconds chunks\n",
    "    for i in range(num_chunks):\n",
    "        chunk_file = f\"{save_in_directory}/{os.path.basename(audio_file).split('.')[0]}_{i}.wav\"\n",
    "        obj = wave.open(chunk_file, \"w\")\n",
    "        obj.setnchannels(num_channels)\n",
    "        obj.setsampwidth(sample_width)\n",
    "        obj.setframerate(frame_rate)\n",
    "        start_frame = int(i * 30 * frame_rate * num_channels * sample_width)\n",
    "        end_frame = int((i + 1) * 30 * frame_rate * num_channels * sample_width)\n",
    "        obj.writeframes(audio_data[start_frame:end_frame])\n",
    "        obj.close()\n",
    "\n",
    "    # Handle the last chunk if there's any leftover\n",
    "    if duration % 30 != 0:\n",
    "        chunk_file = f\"{save_in_directory}/{os.path.basename(audio_file).split('.')[0]}_{num_chunks}.wav\"\n",
    "        obj = wave.open(chunk_file, \"w\")\n",
    "        obj.setnchannels(num_channels)\n",
    "        obj.setsampwidth(sample_width)\n",
    "        obj.setframerate(frame_rate)\n",
    "        start_frame = int(num_chunks * 30 * frame_rate * num_channels * sample_width)\n",
    "        obj.writeframes(audio_data[start_frame:])\n",
    "        obj.close()\n",
    "\n",
    "\n",
    "#executar a função\n",
    "audio_file = 'testeAudios/test2.wav'\n",
    "save_in_directory = './testeAudios/label2'\n",
    "split_audio(audio_file, save_in_directory)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
